!pip install biopython spacy nltk pandas networkx matplotlib
!pip install spacy download en_core_web_sm

from Bio import Entrez
import spacy, re, pandas as pd
import nltk
from nltk.tokenize import word_tokenize
import networkx as nx, matplotlib.pyplot as plt
from nltk.corpus import stopwords
stop = set(stopwords.words('english'))

nltk.download('punkt')
nltk.download('stopwords')

Entrez.email = 'saniya_sayyed_151@gmail.com'
Entrez.api_key = 'YOUR_NCBI_API_KEY' #optional

#skipped reinstallation

def fetch_pubmed_abstracts(query, max_records=3):
    '''Searches Pubmed for a given query, retrieves the pubmed IDs of
    a few matching papers, Fetch thier abstracts and titles,
    Returns:
    in a list of dictionaries'''
    h = Entrez.esearch(db='pubmed', term=query, retmax=max_records)
    ids = Entrez.read(h)['IdList']; h.close()
    if not ids:
        return []
    h = Entrez.efetch(db='pubmed', id=','.join(ids), retmode='xml'); recs = Entrez.read(h); h.close()
    out = []
    for art in recs.get('PubmedArticle', []):
        pmid = str(art['MedlineCitation']['PMID'])
        article = art['MedlineCitation']['Article']
        title = article.get('ArticleTitle','')
        abstract = ''
        if article.get('Abstract'):
            parts = article['Abstract'].get('AbstractText')
            if isinstance(parts, list):
                texts = []
                for p in parts:
                    if isinstance(p, str):
                        texts.append(p)
                    elif isinstance(p, dict):
                        texts.append(p.get('_',''))
                abstract = ' '.join(texts)
            elif isinstance(parts, dict):
                abstract = parts
            elif isinstance(parts, dict):
                abstract = parts.get(' ', '')
        out.append({'pmid': pmid, 'title': str(title), 'abstract': abstract})
    return out

docs = fetch_pubmed_abstracts('Paracetamol headache', max_records=10)
for d in docs:
    print(d['pmid'], '-', d['title'][:120])
